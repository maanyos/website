<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Projects</title>
	<link rel="stylesheet" href="styles/projects.css">
	<link rel="stylesheet" href="styles/common.css">
</head>

<body class="page">
	<nav class="navbar">
		<div class="navbar-external">
			<a href="https://www.linkedin.com/in/kaiwen-zhou/" target="_blank">
				<img class="navbar-external-logo" src="images/linkedin_logo.png">
			</a>

			<a href="https://github.com/maanyos" target="_blank">
				<img class="navbar-external-logo" src="images/github_logo.png">
			</a>
		</div>
		<div class="navbar-sections">
			<ul>
				<li><a href="index.html">About Me</a></li>
				<li><a href="education.html">Education</a></li>
				<li><a href="projects.html" class="navbar-selected">Projects</a></li>
			</ul>
		</div>
	</nav>

	<h1>Projects</h1>

	<div class="project">
		<div class="project-row">
			<div class="project-item project-item-left">
				<h2>Document AI</h2>
				<h4>Machine Learning, Backend Development, Python</h4>
				<div class="project-details">
					2024 (11 months)
					<div class="project-manpower">
						1
						<img class="logo" src="images/person_logo.png">
					</div>
					<a href="https://www.reven.ai/">Reven AI</a>
				</div>
				<div class="project-description">
					Worked in a Canadian startup developing smart solutions to improve healthcare admin processes.
					<h6>Overview</h6>
					Developed a Document AI technology to extract information from medical documents, simplifying tasks
					for healthcare
					staff. The technology includes a multimodal transformer (image-encoder decoder model) for visual
					extraction and a
					post-processor using OpenAI API for cleaning, validation, and reformatting.
					<h6>Contributions</h6>
					<ol>
						<li>Design and implement AI engine system in Python</li>
						<li>Label datasets</li>
						<li>Train model on AWS EC2</li>
						<li>Evaluate engine performance</li>
						<li>Develop post processor</li>
					</ol>
					<h6>Results</h6>
					The AI engine is robust, effectively handling documents with high noise levels, handwriting,
					and information scattered across multiple pages. It achieved an accuracy of over 80% on
					client documents, significantly improving from the previous version's 60% and surpassing
					general-purpose models like GPT-4o, which achieve 55%.
					<img src="images/reven_diagram.jpg" class="project-image">
				</div>

			</div>
			<div class="project-item project-item-right">
				<h2>Single Pilot Cockpit</h2>
				<h4>Computer Vision, Mechatronics, Python, C</h4>
				<div class="project-details">
					2023 (11 months)
					<div class="project-manpower">
						5
						<img class="logo" src="images/person_logo.png">
					</div>
					<a href="https://cde.nus.edu.sg/edic/idp/modules/eg3301r/">NUS Innovation & Design Program</a>
				</div>
				<div class="project-description">
					Partnered with Boeing to explore single pilot cockpit operations in commercial aircrafts.
					<h6>Overview</h6>
					Designed and developed a proof-of-concept solution for a single pilot cockpit using smart glasses
					and an automated cockpit switch system. The solution handles tasks typically performed by a
					co-pilot, such as executing checklists, error detection, and ensuring pilot alertness.
					<h6>Contributions</h6>
					<ol>
						<li>Engaged with Boeing engineers and pilots to understand current cockpit procedures.
						</li>
						<li>Designed functionality of smart glasses and automated switches:</li>
						<ul>
							<li>Overlays critical information such as checklist items and warnings in the pilot's field
								of view.
							</li>
							<li>Tracks the pilot's blinking pattern and wakes them with vibrations if their eyes remain
								closed for an extended period.</li>
							<li>Uses computer vision to detect errors in pilot's actions and alert them accordingly.
							</li>
							<li>Automated switches execute tasks upon pilot approval while maintaining manual override
								capability as backup.</li>
						</ul>
						<li>Sourced and integrated all electronic components, including a mini OLED display, vibration
							motor, motion sensor, video camera, buttons & switches, rotary motors, and
							microcontrollers</li>
						<li>Developed all functionality of smart glasses and automated switches including
							microcontroller algorithm, computer vision, and OLED display content. (Yolov8, Python,
							Arduino)</li>
					</ol>
					<h6>Results</h6>
					The solution offloads lower-level tasks, such as manually flipping switches and looking down at
					cockpit instruments. This helps the pilot to focus on higher level tasks like decision making and
					monitoring the flight path, thus improving the pilot's situational awareness and flight safety.
					<video class="project-video" src="images/cockpit_video.mp4" controls>
						Your browser does not support this video format.
					</video>
				</div>

			</div>
		</div>

		<div class="project-row">
			<div class="project-item project-item-right">
				<h2>Robotics Car</h2>
				<h4>Robotics, Real-Time Operating System, C</h4>
				<div class="project-details">
					2023 (3 months)
					<div class="project-manpower">
						5
						<img class="logo" src="images/person_logo.png">
					</div>
					<a href="">NUS Computer Engineering</a>
				</div>
				<div class="project-description">
					<h6>Overview</h6>
					<h6>Contributions</h6>
					<h6>Results</h6>
					fastest lap time in class
					• Building a remoted controlled car for driving around a test circuit.
					• The main microcontroller (FRDM KL25Z) contains an ARM Cortex M0+ processor
					and runs a Real-Time Operating System (Keil RTX), programmed with threads and
					interrupts. (C)
					• The robot is controlled via an Android web app that interfaces over Wi-Fi with the onboard ESP32
					microcontroller,
					which then relays information to the main
					microcontroller over UART.
				</div>
			</div>
			<div class="project-item project-item-left">
				<h2>Robot Autonomous Exploration</h2>
				<h4>Robotics, C++</h4>
				<div class="project-details">
					2023 (3 months)
					<div class="project-manpower">
						10+
						<img class="logo" src="images/person_logo.png">
					</div>
					<a href="">Defence Science and Technology Agency</a>
				</div>
				<div class="project-description">
					<h6>Overview</h6>
					<h6>Contributions</h6>
					<h6>Results</h6>
					gps localisation
					• Developed robotics solutions for military applications.
					• Developed GPS-based localization capability and automated exploration procedure
					for autonomous exploration with legged robot. (ROS1&2, C++)
					• Designed overall system process & structure and implemented object tracking using
					computer vision to allow autonomous navigation with drones. (Python, Yolov8)
				</div>
			</div>
		</div>

		<div class="project-row">
			<div class="project-item project-item-left">
				<h2>Drone Autonomous Navigation</h2>
				<h4>Computer Vision, Python</h4>
				<div class="project-details">
					2023 (3 months)
					<div class="project-manpower">
						2
						<img class="logo" src="images/person_logo.png">
					</div>
					<a href="">Defence Science and Technology Agency</a>
				</div>
				<div class="project-description">
					<h6>Overview</h6>
					<h6>Contributions</h6>
					<h6>Results</h6>
					semi automate navigation
				</div>
			</div>
			<div class="project-item project-item-right">
				<h2>RC Tank</h2>
				<h4>Robotics, Real-Time Operating System, C</h4>
				<div class="project-details">
					In progress (since 2024)
					<div class="project-manpower">
						1
						<img class="logo" src="images/person_logo.png">
					</div>
					Personal Project
				</div>
				<div class="project-description">
					<h6>Overview</h6>
					<h6>Contributions</h6>
					<h6>Results</h6>
					design manufacture assemble
				</div>
			</div>
		</div>

	</div>

</body>

</html>